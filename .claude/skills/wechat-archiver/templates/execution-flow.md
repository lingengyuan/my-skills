# Execution Flow Template

## Overview

æ­¤æ¨¡æ¿å®šä¹‰ `wechat-archiver` skill çš„å®Œæ•´æ‰§è¡Œæµç¨‹ã€‚å®ç°æ—¶ä¸¥æ ¼æŒ‰æ­¤é¡ºåºæ‰§è¡Œã€‚

---

## Step 0: Input Validation

**Input**: `article_url`, `target_folder`, `force`, `canvas`, `base`

### 0.1 Validate URL

```python
def validate_wechat_url(url: str) -> bool:
    """
    éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„å¾®ä¿¡å…¬ä¼—å· URL
    """
    from urllib.parse import urlparse

    parsed = urlparse(url)

    # æ£€æŸ¥åŸŸå
    if parsed.netloc not in ["mp.weixin.qq.com", "weixin.qq.com"]:
        raise ValueError(f"Invalid WeChat URL domain: {parsed.netloc}")

    # æ£€æŸ¥è·¯å¾„æ ¼å¼ (é€šå¸¸ä¸º /s/<xxxxx>)
    if not parsed.path.startswith("/s/"):
        raise ValueError(f"Invalid WeChat URL path: {parsed.path}")

    return True
```

**Error**: å¦‚æœéªŒè¯å¤±è´¥ï¼Œç«‹å³è¿”å›é”™è¯¯ï¼Œä¸æ‰§è¡Œåç»­æ­¥éª¤ã€‚

### 0.2 Set Default Values

```python
# Default values
if target_folder is None:
    target_folder = "20-é˜…è¯»ç¬”è®°"

if force is None:
    force = False

if canvas is None:
    canvas = "auto"

if base is None:
    base = "auto"
```

---

## Step 1: Call wechat2md

**Command**:
```bash
python3 .claude/skills/wechat2md/tools/wechat2md.py "<article_url>"
```

### 1.1 Capture Output

```python
import subprocess
from pathlib import Path

def run_wechat2md(url: str) -> dict:
    """
    è°ƒç”¨ wechat2md å¹¶è¿”å›è¾“å‡ºè·¯å¾„
    """
    skill_dir = Path(".claude/skills/wechat2md")
    script = skill_dir / "tools" / "wechat2md.py"

    result = subprocess.run(
        ["python3", str(script), url],
        capture_output=True,
        text=True,
        cwd=Path.cwd()
    )

    if result.returncode != 0:
        raise RuntimeError(f"wechat2md failed: {result.stderr}")

    # Parse output (last line should be the md path)
    output_lines = result.stdout.strip().split("\n")
    md_path = output_lines[-1] if output_lines else None

    # Infer paths
    md_path = Path(md_path)
    title = md_path.stem  # filename without extension
    temp_md_path = md_path
    temp_images_dir = Path.cwd() / "images" / title

    return {
        "title": title,
        "temp_md_path": temp_md_path,
        "temp_images_dir": temp_images_dir
    }
```

### 1.2 Handle Errors

- If `wechat2md` fails â†’ è®°å½•é”™è¯¯åˆ° `run.jsonl`ï¼Œè¿”å›å¤±è´¥çŠ¶æ€
- Do NOT create asset directory

---

## Step 2: Generate Asset ID and Slug

```python
import hashlib
from datetime import datetime
from .rules.idempotency import normalize_url, generate_asset_id, sanitize_title, generate_slug

def generate_asset_metadata(article_url: str, article_title: str) -> dict:
    """
    ç”Ÿæˆèµ„äº§çš„å”¯ä¸€æ ‡è¯†
    """
    asset_id = generate_asset_id(article_url)
    slug = generate_slug(article_title, asset_id)

    return {
        "asset_id": asset_id,
        "slug": slug,
        "url": article_url,
        "title": article_title
    }
```

---

## Step 3: Create Asset Directory

```python
from pathlib import Path

def create_asset_directory(cwd: Path, target_folder: str, slug: str) -> Path:
    """
    åˆ›å»ºç»Ÿä¸€çš„èµ„äº§ç›®å½•
    """
    asset_dir = cwd / "outputs" / target_folder / slug
    asset_dir.mkdir(parents=True, exist_ok=True)

    return asset_dir
```

**Path**: `<cwd>/outputs/<target_folder>/<slug>/`

---

## Step 4: Consolidate Files

```python
import shutil

def consolidate_files(
    asset_dir: Path,
    temp_md_path: Path,
    temp_images_dir: Path
) -> None:
    """
    ç»Ÿä¸€æ–‡ä»¶åˆ°èµ„äº§ç›®å½•
    """
    # Copy article.md
    shutil.copy2(temp_md_path, asset_dir / "article.md")

    # Copy images directory
    if temp_images_dir.exists():
        shutil.copytree(temp_images_dir, asset_dir / "images", dirs_exist_ok=True)

    # Cleanup: remove wechat2md temp output
    # Note: be careful to only remove temp files, not the asset_dir
    temp_output_dir = temp_md_path.parent
    if temp_output_dir != asset_dir:
        shutil.rmtree(temp_output_dir, ignore_errors=True)

    # Cleanup temp images
    if temp_images_dir != asset_dir / "images":
        shutil.rmtree(temp_images_dir, ignore_errors=True)
```

---

## Step 5: Calculate Hash and Check Idempotency

```python
from .rules.idempotency import hash_article_content, check_idempotency

def check_should_generate(asset_dir: Path, force: bool) -> dict:
    """
    æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆç¬”è®°
    """
    # Calculate hash
    article_path = asset_dir / "article.md"
    hash_content = hash_article_content(str(article_path))

    # Check idempotency
    decision = check_idempotency(str(asset_dir), hash_content, force)

    return {
        "hash_content": hash_content,
        "should_generate": decision["should_generate"],
        "reason": decision["reason"]
    }
```

**Decision**:
- If `should_generate == False` â†’ è·³åˆ° Step 9 (è®°å½•æ—¥å¿—å¹¶è¿”å›)
- If `should_generate == True` â†’ ç»§ç»­ Step 6

---

## Step 6: Decide Artifact Plan

```python
from .rules.classification import decide_artifact_plan, decide_diagram_type, decide_base_mode

def decide_plan(article_path: Path, canvas: str, base: str) -> dict:
    """
    å†³å®šç”Ÿæˆå“ªäº›äº§ç‰©
    """
    # Read article content
    with open(article_path, "r", encoding="utf-8") as f:
        content = f.read()

    # Decide artifact plan
    artifact_plan = decide_artifact_plan(content, canvas, base)

    # Decide specific types
    if "canvas" in artifact_plan:
        diagram_type = decide_diagram_type(content)
    else:
        diagram_type = None

    if "base" in artifact_plan:
        base_mode = decide_base_mode(content)
    else:
        base_mode = None

    return {
        "artifact_plan": artifact_plan,
        "diagram_type": diagram_type,
        "base_mode": base_mode
    }
```

---

## Step 7: Call note-creator

**Input Preparation**:

```python
def prepare_note_creator_input(
    asset_dir: Path,
    article_metadata: dict,
    plan: dict
) -> dict:
    """
    å‡†å¤‡è°ƒç”¨ note-creator çš„è¾“å…¥
    """
    # Generate summary prompt from article
    article_path = asset_dir / "article.md"
    with open(article_path, "r", encoding="utf-8") as f:
        article_content = f.read()

    # Extract first paragraph as summary
    first_para = article_content.split("\n\n")[0][:200]

    user_prompt = f"""
    è¯·ä¸ºä»¥ä¸‹å¾®ä¿¡æ–‡ç« ç”Ÿæˆç»“æ„åŒ–ç¬”è®°ï¼š

    æ ‡é¢˜ï¼š{article_metadata['title']}
    æ¥æºï¼šå¾®ä¿¡å…¬ä¼—å·
    æ‘˜è¦ï¼š{first_para}

    æ–‡ç« å†…å®¹ï¼šè§ article.md

    è¦æ±‚ï¼š
    1. ç”Ÿæˆ note.mdï¼ˆç»“æ„åŒ–ç¬”è®°ï¼‰
    2. {"ç”Ÿæˆ diagram.canvasï¼ˆ" + plan['diagram_type'] + "ç±»å‹å›¾ï¼‰" if 'canvas' in plan['artifact_plan'] else "ä¸ç”Ÿæˆ canvas"}
    3. {"ç”Ÿæˆ table.baseï¼ˆ" + plan['base_mode'] + "æ¨¡å¼ï¼‰" if 'base' in plan['artifact_plan'] else "ä¸ç”Ÿæˆ base"}

    è¾“å‡ºåˆ°åŒä¸€ç›®å½•ï¼š{asset_dir}
    """

    return {
        "user_prompt": user_prompt.strip(),
        "optional_context_files": [str(article_path)],
        "runtime_context": {
            "title": article_metadata['title'],
            "folder": Path(asset_dir).parent.name,  # e.g., "20-é˜…è¯»ç¬”è®°"
            "artifact_plan": plan['artifact_plan'],
            "diagram_type": plan['diagram_type'],
            "base_mode": plan['base_mode'],
            "output_to_same_dir": True,
            "target_dir": str(asset_dir)
        }
    }
```

**Invocation**: (é€šè¿‡ Claude Code Skill æœºåˆ¶è°ƒç”¨)

```
Skill(note-creator) with prepared input
```

**Expected Output**:
- `note.md` in asset_dir
- `diagram.canvas` (if in artifact_plan)
- `table.base` (if in artifact_plan)
- `meta.json` (note-creator's metadata)

### 7.1 Handle note-creator Errors

```python
# If note-creator fails:
# 1. Preserve article.md and images/
# 2. Log error to run.jsonl
# 3. Mark meta.json with "failed" status
# 4. Return partial success to user
```

---

## Step 8: Merge meta.json

```python
import json
from datetime import datetime

def merge_meta_files(
    asset_dir: Path,
    article_metadata: dict,
    hash_content: str,
    plan: dict,
    decision: dict
) -> None:
    """
    åˆå¹¶å…ƒæ•°æ®
    """
    meta_path = asset_dir / "meta.json"

    # Read note-creator's meta (if exists)
    note_meta = {}
    if meta_path.exists():
        with open(meta_path, "r", encoding="utf-8") as f:
            note_meta = json.load(f)

    # Build unified meta
    unified_meta = {
        # Asset identification
        "asset_id": article_metadata['asset_id'],
        "url": article_metadata['url'],
        "title": article_metadata['title'],
        "slug": article_metadata['slug'],

        # Hash
        "hash_content": hash_content,
        "hash_algorithm": "sha256",

        # Timestamps
        "ingested_at": datetime.now().isoformat(),
        "published_at": note_meta.get("published_at"),  # extracted by note-creator

        # Artifact plan
        "artifact_plan": plan['artifact_plan'],

        # Note-creator metadata (merge)
        "category": note_meta.get("category", "article"),
        "tags": note_meta.get("tags", []),
        "properties": note_meta.get("properties", {}),

        # Run info
        "last_run_at": datetime.now().isoformat(),
        "last_run_status": "success",
        "last_run_reason": decision['reason'],
        "run_count": note_meta.get("run_count", 0) + 1,

        # Version
        "meta_version": "1.0"
    }

    # Preserve hash history if updating
    if "hash_history" in note_meta:
        unified_meta["hash_history"] = note_meta["hash_history"]

    # Write unified meta
    with open(meta_path, "w", encoding="utf-8") as f:
        json.dump(unified_meta, f, ensure_ascii=False, indent=2)
```

---

## Step 9: Record run.jsonl

```python
import json
import time

def append_run_log(
    asset_dir: Path,
    asset_id: str,
    action: str,
    status: str,
    reason: str,
    hash_content: str,
    artifact_plan: list,
    duration_ms: int,
    error: str = None
) -> None:
    """
    è¿½åŠ è¿è¡Œæ—¥å¿—
    """
    log_path = asset_dir / "run.jsonl"

    log_entry = {
        "timestamp": datetime.now().isoformat(),
        "action": action,  # ingest | update | skip | fail
        "asset_id": asset_id,
        "status": status,  # success | failed | skipped
        "reason": reason,
        "hash_content": hash_content,
        "artifact_plan": artifact_plan,
        "duration_ms": duration_ms,
        "error": error
    }

    # Append to file (create if not exists)
    with open(log_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
```

---

## Step 10: Return Summary

```python
def format_success_summary(asset_dir: Path, plan: dict, status: str) -> str:
    """
    æ ¼å¼åŒ–æ‰§è¡Œæ‘˜è¦
    """
    lines = [
        "",
        "=" * 50,
        "âœ… å¾®ä¿¡æ–‡ç« å½’æ¡£æˆåŠŸ",
        "=" * 50,
        f"ğŸ“ èµ„äº§ç›®å½•: {asset_dir}",
        f"ğŸ“Š çŠ¶æ€: {status}",
        ""
    ]

    # List generated files
    files = []
    for file in ["article.md", "note.md", "diagram.canvas", "table.base", "meta.json", "run.jsonl"]:
        file_path = asset_dir / file
        if file_path.exists():
            files.append(f"  âœ“ {file}")

    lines.append("ğŸ“„ ç”Ÿæˆçš„æ–‡ä»¶:")
    lines.extend(files)
    lines.append("")

    # Hints for optional artifacts
    if "canvas" in plan['artifact_plan']:
        lines.append("ğŸ’¡ æç¤º: å·²ç”Ÿæˆ diagram.canvasï¼Œå¯åœ¨ Obsidian ä¸­æ‰“å¼€æŸ¥çœ‹")
    if "base" in plan['artifact_plan']:
        lines.append("ğŸ’¡ æç¤º: å·²ç”Ÿæˆ table.baseï¼Œå¯åœ¨ Obsidian ä¸­ä»¥è¡¨æ ¼å½¢å¼æŸ¥çœ‹")

    lines.append("=" * 50)
    lines.append("")

    return "\n".join(lines)
```

---

## Complete Execution Flow (Pseudo-code)

```python
def wechat_archiver_main(
    article_url: str,
    target_folder: str = None,
    force: bool = False,
    canvas: str = "auto",
    base: str = "auto"
) -> dict:
    """
    Main execution flow
    """
    start_time = time.time()
    asset_id = None
    action = "ingest"

    try:
        # Step 0: Validate input
        validate_wechat_url(article_url)
        target_folder = target_folder or "20-é˜…è¯»ç¬”è®°"

        # Step 1: Call wechat2md
        wechat_result = run_wechat2md(article_url)

        # Step 2: Generate asset metadata
        asset_meta = generate_asset_metadata(article_url, wechat_result['title'])
        asset_id = asset_meta['asset_id']

        # Step 3: Create asset directory
        cwd = Path.cwd()
        asset_dir = create_asset_directory(cwd, target_folder, asset_meta['slug'])

        # Step 4: Consolidate files
        consolidate_files(asset_dir, wechat_result['temp_md_path'], wechat_result['temp_images_dir'])

        # Step 5: Check idempotency
        hash_check = check_should_generate(asset_dir, force)
        hash_content = hash_check['hash_content']

        if not hash_check['should_generate']:
            # Skip note-creator
            action = "skip"
            duration_ms = int((time.time() - start_time) * 1000)
            append_run_log(
                asset_dir, asset_id, action, "skipped",
                hash_check['reason'], hash_content, [], duration_ms
            )
            return {
                "status": "skipped",
                "asset_dir": str(asset_dir),
                "reason": hash_check['reason']
            }

        # Step 6: Decide artifact plan
        plan = decide_plan(asset_dir / "article.md", canvas, base)

        # Step 7: Call note-creator
        note_creator_input = prepare_note_creator_input(asset_dir, asset_meta, plan)
        # Actual invocation via Skill(note-creator)
        invoke_note_creator(note_creator_input)

        # Step 8: Merge meta.json
        merge_meta_files(asset_dir, asset_meta, hash_content, plan, hash_check)

        # Step 9: Record run.jsonl
        duration_ms = int((time.time() - start_time) * 1000)
        append_run_log(
            asset_dir, asset_id, action, "success",
            hash_check['reason'], hash_content, plan['artifact_plan'], duration_ms
        )

        # Step 10: Return summary
        return {
            "status": "success",
            "asset_dir": str(asset_dir),
            "artifact_plan": plan['artifact_plan'],
            "reason": hash_check['reason']
        }

    except Exception as e:
        # Handle error
        duration_ms = int((time.time() - start_time) * 1000)
        error_msg = f"{type(e).__name__}: {e}"

        # Log error if asset_dir exists
        if asset_dir and asset_dir.exists():
            append_run_log(
                asset_dir, asset_id, action, "failed",
                "error", "", [], duration_ms, error_msg
            )

        return {
            "status": "failed",
            "error": error_msg
        }
```

---

## Summary

**Execution Order** (MUST follow):
1. âœ… Validate URL
2. âœ… Call wechat2md
3. âœ… Generate asset_id + slug
4. âœ… Create asset directory
5. âœ… Consolidate files (article.md + images/)
6. âœ… Calculate hash + check idempotency
7. âœ… Decide artifact plan (auto canvas/base)
8. âœ… Call note-creator (if needed)
9. âœ… Merge meta.json
10. âœ… Record run.jsonl
11. âœ… Return summary

**Critical Invariants**:
- All files in one directory
- Idempotency MUST be respected
- Original article MUST be preserved
- Logs MUST be appended (not overwritten)
